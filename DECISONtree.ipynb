{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "The dataset used in this project aims to predict the occurrence of a stroke based on various health-related factors. Each feature represents an aspect of the patient's health, such as age, hypertension status, smoking habits, etc. The target variable is `stroke`, which is a binary classification indicating whether a stroke occurred.\n",
    "\n",
    "Key features:\n",
    "- `age`: The age of the patient.\n",
    "- `hypertension`: Indicates whether the patient has hypertension (1) or not (0).\n",
    "- `heart_disease`: Indicates the presence (1) or absence (0) of heart disease.\n",
    "- `avg_glucose_level`: The average glucose level in the blood.\n",
    "- `bmi`: Body Mass Index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DATA/healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration (Visualizations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=30, figsize=(15, 10))\n",
    "plt.suptitle('Feature Distributions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_data(df):\n",
    "    total=df.isnull().sum().sort_values(ascending=False)\n",
    "    percent=(df.isnull().sum()/df.isnull().count() * 100).sort_values(ascending=False)\n",
    "    missing_data=pd.concat([total,percent],axis=1,keys=[\"total\",\"Percent\"])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bmi\"].fillna(df[\"bmi\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stroke'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('stroke',axis=1)\n",
    "y=df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the number of unique values in each column\n",
    "print(\"Unique values in each column are:\")\n",
    "for col in df.columns:\n",
    "    print(col,df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname_num=[]\n",
    "for x in df.columns:\n",
    "    if df[x].dtype=='object':\n",
    "        colname_num.append(x)\n",
    "colname_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables.\n",
    "\n",
    "-Since the dataset contains categorical variables, we need to convert these into a numerical format to be used by the machine learning model. We use `LabelEncoder` for this purpose, which transforms categorical data into a format that can be provided to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for x in colname_num:\n",
    "    df[x]=le.fit_transform(df[x])\n",
    "    \n",
    "    print()\n",
    "    le_name_mapping = dict(zip(le.classes_,le.transform(le.classes_)))\n",
    "    print('Feature',x)\n",
    "    print('mapping',le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('stroke',axis=1)\n",
    "y=df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('stroke',axis=1), df['stroke'], test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='entropy',max_depth=10,min_samples_leaf=20,min_samples_split=15,splitter='best')\n",
    "dtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training Accuracy:\",dtree.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "\n",
    "dtree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = dtree.predict(X_test)\n",
    "accuracy_score(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm =confusion_matrix(y_test,dt_pred)\n",
    "\n",
    "print(cfm)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "\n",
    "print(classification_report(y_test,dt_pred))\n",
    "\n",
    "acc=accuracy_score(y_test, dt_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(\"-------------{}-------------\".format(i))\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The Decision Tree model was effectively used to predict stroke occurrences based on various health indicators. The model achieved a reasonable accuracy, but there is potential for further improvement through hyperparameter tuning, feature engineering, and handling class imbalance. Overall, the analysis provided insights into the most significant factors contributing to stroke risk, offering a foundation for more advanced models and applications in predictive healthcare.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watsappahel",
   "language": "python",
   "name": "watsappahel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
